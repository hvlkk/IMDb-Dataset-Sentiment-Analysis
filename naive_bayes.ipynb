{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "264b9c285a3596fe",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Naive Bayes\n",
    "We will be implementing the Bernoulli version of Naive Bayes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0c77554be48b7f7",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Hyperparameter tweaking\n",
    "Following the assignment guidelines, we will be tweaking three hyperparameters throughout the testing of the project; m (for the size of the vocabulary), n (for the n most common words in the training data), and k (for the k least common words in the training data), the last 2 of which will not be included in the vocabulary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "77b07ece71a8dfc0",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-06T23:17:39.009156700Z",
     "start_time": "2024-01-06T23:17:38.999101300Z"
    }
   },
   "outputs": [],
   "source": [
    "m = 2000\n",
    "n = 200\n",
    "k = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae2e294f3fccfc94",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Fetch data\n",
    "Fetching the reviews, while taking into account the aforementioned m, n and k hyperparameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "cea894557c4dba2e",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-06T23:17:46.312431Z",
     "start_time": "2024-01-06T23:17:40.480563700Z"
    }
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "# fetching the reviews\n",
    "(x_train_raw, y_train), (x_test_raw, y_test) = tf.keras.datasets.imdb.load_data(num_words=m-k, skip_top=n)\n",
    "\n",
    "# make a dictionary out of the words provided according to the above conditions \n",
    "word_index = tf.keras.datasets.imdb.get_word_index()\n",
    "index2word = dict((i + 3, word) for (word, i) in word_index.items())\n",
    "index2word[0] = '[pad]'\n",
    "index2word[1] = '[bos]'\n",
    "index2word[2] = '[oov]'\n",
    "\n",
    "# x_train and x_test will consist of strings that represent reviews, but limited to the dictionary provided\n",
    "x_train_text = np.array([' '.join([index2word[idx] for idx in text]) for text in x_train_raw])\n",
    "x_test_text = np.array([' '.join([index2word[idx] for idx in text]) for text in x_test_raw])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb0a24fe9a0b253",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Vectorize data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "a0b6807fc7a137cb",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-06T23:17:57.623362300Z",
     "start_time": "2024-01-06T23:17:50.590354500Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary size: 1670\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "binary_vectorizer = CountVectorizer(binary=True)\n",
    "\n",
    "# transforming the train and test text reviews into binary matrices\n",
    "x_train_binary = binary_vectorizer.fit_transform(x_train_text)\n",
    "x_test_binary = binary_vectorizer.transform(x_test_text)\n",
    "\n",
    "feature_names = binary_vectorizer.get_feature_names_out()\n",
    "\n",
    "x_train = np.array(x_train_binary.toarray())\n",
    "x_test = np.array(x_test_binary.toarray())"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Information Gain"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a90033c65711734d"
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "def information_gain(class_, feature):\n",
    "    classes = set(class_)\n",
    "\n",
    "    Hc = 0\n",
    "    for c in classes:\n",
    "        pc = list(class_).count(c)/len(class_)\n",
    "        Hc += - pc * math.log(pc, 2)\n",
    "    print('Overall Entropy:', Hc)\n",
    "    feature_values = set(feature)\n",
    "\n",
    "    hc_feature = 0\n",
    "    for feat in feature_values:\n",
    "\n",
    "        #pf --> P(X=x)\n",
    "        pf = list(feature).count(feat)/len(feature)\n",
    "        indices = [i for i in range(len(feature)) if feature[i] == feat]\n",
    "        classes_of_feat = [class_[i] for i in indices]\n",
    "        for c in classes:\n",
    "            #pcf --> P(C=c|X=x)\n",
    "            pcf = classes_of_feat.count(c)/len(classes_of_feat)\n",
    "            if pcf != 0:\n",
    "                # - P(X=x) * P(C=c|X=x) * log2(P(C=c|X=x))\n",
    "                temp_H = - pf * pcf * math.log(pcf, 2)\n",
    "                #sum for all values of C (class) and X (values of specific feature)\n",
    "                hc_feature += temp_H\n",
    "    ig = Hc - hc_feature\n",
    "    return ig"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-06T23:18:22.682461400Z",
     "start_time": "2024-01-06T23:18:22.677462900Z"
    }
   },
   "id": "8c0dc7c13be35728"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Bernoulli Naive Bayes"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "47ecd3a4031b37ca"
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "outputs": [],
   "source": [
    "class BernoulliNaiveBayes:\n",
    "    def __init__(self):\n",
    "        \"\"\"\n",
    "        apriori_positive: Initialised to the total number of positive reviews / the total number of reviews from our training data\n",
    "        apriori_negative: Initialised to the total number of negative reviews / the total number of reviews from our training data\n",
    "        \"\"\"\n",
    "        self.apriori_positive = None\n",
    "        self.apriori_negative = None\n",
    "        self.positive_category_feature_exists = None\n",
    "        self.negative_category_feature_exists = None\n",
    "    \n",
    "    def fit(self, x, y):\n",
    "        alpha = 1   # the parameter used for Laplace smoothing\n",
    "        \n",
    "        num_train_data = x.shape[0]\n",
    "        num_features = x.shape[1]\n",
    "                \n",
    "        # apriori_positive/negative: p(C=1)/p(C=0) respectively for the training data\n",
    "        self.apriori_positive = len(np.where(y == 1)[0]) / len(y)\n",
    "        self.apriori_negative = len(np.where(y == 0)[0]) / len(y)\n",
    "        \n",
    "        \"\"\"\n",
    "        positive_category_feature_exists/negative_category_feature_exists are two arrays of size equal to the total amount\n",
    "        of features (words in the vocabulary), with each index representing the probability the category will be positive\n",
    "        or negative respectively, given that the feature in that specific index is present in the training data. \n",
    "        \"\"\"        \n",
    "        self.positive_category_feature_exists = (np.sum(x[y == 1], axis=0) + alpha) / (len(np.where(y == 1)) + 2 * alpha)\n",
    "        self.negative_category_feature_exists = (np.sum(x[y == 0], axis=0) + alpha) / (len(np.where(y == 0)) + 2 * alpha)     \n",
    "        \n",
    "        return self\n",
    "        "
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-06T23:36:39.931653800Z",
     "start_time": "2024-01-06T23:36:39.919625100Z"
    }
   },
   "id": "5212408abab69516"
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12500\n",
      "Sum: 12500\n",
      "Length: 12500\n",
      "False\n",
      "(1670,)\n",
      "1670\n"
     ]
    },
    {
     "data": {
      "text/plain": "<__main__.BernoulliNaiveBayes at 0x1dfce538760>"
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bernoulli_nb = BernoulliNaiveBayes()\n",
    "bernoulli_nb.fit(x_train, y_train)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-06T23:29:01.662516800Z",
     "start_time": "2024-01-06T23:29:01.391396900Z"
    }
   },
   "id": "982f5669a77ef086"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
